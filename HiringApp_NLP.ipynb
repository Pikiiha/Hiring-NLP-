{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HiringApp_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BnTE8fJ35rXW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94PhLbg4tV_r",
        "colab_type": "text"
      },
      "source": [
        "##Overview of project \n",
        "This notebook is steps in bold.\n",
        "1. **Extract text from PDF Resumes**\n",
        "2. Build an API for Angel.co for job listings (or Indeed API)\n",
        "3. **Use Cosine similarity to match resumes to job postings**\n",
        "4. **Review Scoring with Data Visualizations and comparisons**\n",
        "5. Convert into a Streamlit app "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKbvy9nA3z-1",
        "colab_type": "text"
      },
      "source": [
        "## Step 1. Convert pdf resume to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqYFf-x3w8NB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.summarization import keywords\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1EEoaPn5Mr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "77bb291b-820f-40b2-dbdd-ead7a653bedb"
      },
      "source": [
        "#install pdf reader module\n",
        "! pip install pdfminer.six"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer.six\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/12/ab5ebafc4cb2b49847de7bfc26f2d152f42a4af136263152d070c61dfd7d/pdfminer.six-20200726-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 121kB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdfminer.six) (2.2.2)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/91/84a29d6a27fd6dfc21f475704c4d2053d58ed7a4033c2b0ce1b4ca4d03d9/cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.6/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->pdfminer.six) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->pdfminer.six) (2.20)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-3.0 pdfminer.six-20200726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVrknXC68y4w",
        "colab_type": "text"
      },
      "source": [
        "Download the test pdf resume."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q78mSBSP47ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#click the below link and download pdf file from to your local machine\n",
        "#'https://raw.githubusercontent.com/AVJdataminer/HireOne/master/data/Binoy_Dutt_Resume.pdf'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLRmDMMh8lHg",
        "colab_type": "text"
      },
      "source": [
        "Then upload the pdf resume you downloaded to your colab content folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMpKMnPA8don",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "78afe61f-5edc-4933-bc63-d4cd65f6665e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload() # then browse, select the files. It's then uploaded\n",
        "\n",
        "# uploaded is now a dict containing \"filename\" -> Content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-29a4d3b0-85a4-4979-b38e-7c733b22da9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-29a4d3b0-85a4-4979-b38e-7c733b22da9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSMbae635Zzg",
        "colab_type": "text"
      },
      "source": [
        "Convert the pdf resume to text strings and print the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsKQWFuc5YKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "#test out reading one pdf file\n",
        "text = extract_text('Binoy_Dutt_Resume.pdf')\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnTE8fJ35rXW",
        "colab_type": "text"
      },
      "source": [
        "## **Step 2. Still not working , ignore this section for now.** -  Create an Angel.co job listing API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjpaG1Pm9FUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a87a139f-ef0e-4f96-8a79-c17ae88b773e"
      },
      "source": [
        "#install selenium\n",
        "#! pip install selenium"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWfBKjMm9_w_",
        "colab_type": "text"
      },
      "source": [
        "Installing the chromium webdriver and adjusting some options such that it does not crash in google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtJDT2Yb6jjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQmIcyOI_8ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another set of tools to try to get API query to work in Google Colab\n",
        "!pip install kora -q\n",
        "from kora.selenium import wd\n",
        "wd.get(\"https://www.webite-url.com\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKMtQXDV--15",
        "colab_type": "text"
      },
      "source": [
        "Build the API query function first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KMmANMQiNYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_results(query, type_=None, stage=None, tech=None):\n",
        "    \n",
        "#     tech is possible only if type not None, same for others\n",
        "\n",
        "    if type_:\n",
        "        type_ = type_.replace(' ', '+')\n",
        "        url = 'https://angel.co/companies' + '?company_types[]=' + type_\n",
        "        if stage:\n",
        "            url = url + '&stage=' + stage\n",
        "            if tech:\n",
        "                url = url + '&teches[]=' + tech\n",
        "    else:  \n",
        "        url = 'https://angel.co/companies' \n",
        "\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('headless')\n",
        "    \n",
        "    driver = webdriver.Chrome(options=None)\n",
        "    driver.set_window_position(3000,0)\n",
        "    driver.get(url)\n",
        "    time.sleep(5)\n",
        "    \n",
        "    search_box = driver.find_element_by_class_name(\"search-box\")\n",
        "    search_box.click()\n",
        "    \n",
        "    input_bar = driver.find_element_by_class_name('keyword-input')\n",
        "    input_bar.send_keys(query)\n",
        "    input_bar.send_keys(Keys.ENTER)\n",
        "    time.sleep(3)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            source = driver.page_source\n",
        "            loadMoreButton = driver.find_element_by_class_name('more').click()\n",
        "            time.sleep(4)\n",
        "        except: \n",
        "            break\n",
        "            \n",
        "    driver.close()\n",
        "\n",
        "    try:\n",
        "        soup = bs.BeautifulSoup(source, 'lxml')\n",
        "        result_list =  soup.find_all('div', {'class': 'results'})[0]\n",
        "        results = result_list.find_all('div', {'data-_tn': 'companies/row'})\n",
        "    except:\n",
        "        print('Could not get results')\n",
        "        return\n",
        "\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def parse_results(results):\n",
        "    df = pd.DataFrame(columns=['kind', 'link', 'name', 'pitch', 'joined', 'location', 'market', 'size', 'stage', 'raised'],\n",
        "                  index=[0])\n",
        "    for result in results[1:]:\n",
        "        try:\n",
        "            dic = {}\n",
        "            try:\n",
        "                dic['kind'] = result.a['data-type']\n",
        "            except: dic['kind'] = None\n",
        "\n",
        "            try:\n",
        "                dic['link'] = result.a['href']\n",
        "            except: dic['link'] = None\n",
        "\n",
        "            try:\n",
        "                dic['name'] = result.a['title']\n",
        "            except: dic['name'] = None\n",
        "                \n",
        "            try:\n",
        "                dic['website'] = result.find('div', {'data-column': 'website'}).text.split()[1]\n",
        "            except: dic['website'] = None\n",
        "\n",
        "            try:\n",
        "                dic['pitch'] = result.find('div', {'class': 'pitch'}).text\n",
        "            except: dic['pitch'] = None\n",
        "\n",
        "            try:\n",
        "                dic['joined'] = result.find('div', {'data-column': 'joined'}).text.split('Joined')[1].strip()\n",
        "            except: dic['joined'] = None\n",
        "\n",
        "            try:\n",
        "                dic['location'] = result.find('div', {'data-column': 'location'}).text.split('Location')[1].strip()\n",
        "            except: dic['location'] = None\n",
        "\n",
        "            try:\n",
        "                dic['market'] = result.find('div', {'data-column': 'market'}).text.split('Market')[1].strip()\n",
        "            except: dic['market'] = None\n",
        "\n",
        "            try:\n",
        "                dic['size'] = result.find('div', {'data-column': 'company_size'}).text.split()[1]\n",
        "            except: dic['size'] = None\n",
        "\n",
        "            try:\n",
        "                dic['stage'] = result.find('div', {'data-column': 'stage'}).text.split('Stage')[1].strip()\n",
        "            except: dic['stage'] = None\n",
        "\n",
        "            try:\n",
        "                dic['raised'] = result.find('div', {'data-column': 'raised'}).text.split('Raised')[1].strip()\n",
        "            except: dic['raised'] = None\n",
        "\n",
        "            df = df.append(pd.DataFrame(dic, index=[0]))\n",
        "\n",
        "        except: pass\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def get_companies(query, type_=None, stage=None, tech=None):\n",
        "    results = get_results(query, type_, stage, tech)\n",
        "    if results:\n",
        "        df = parse_results(results)\n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l53rMseR_FG6",
        "colab_type": "text"
      },
      "source": [
        "Set up the queries for different ML and AI topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5XKfD0yiNY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d2a8b3e-ce28-4bf1-cbd2-1db7df1664bf"
      },
      "source": [
        "queries = ['artificial intelligence', 'machine learning', 'data science', 'big data', 'neural network', \n",
        "           'deep learning', 'natural language processing', 'transfer learning', 'reinforcement learning',\n",
        "           'nlp', 'recurrent neural', 'convolution neural', 'data mining', 'data extraction', \n",
        "           'data engineering', 'web scraping', 'web scrape', 'web crawler', 'web crawling',\n",
        "           'evolutionary computation', 'genetic algorithm', 'genetic programming', 'object recognition',\n",
        "           'image understanding', 'speech processing', ' speech recognition', 'machine translation', \n",
        "           'time series', 'ai', 'intelligent machine', 'pattern recognition', 'computer vision']\n",
        "\n",
        "\n",
        "types = ['Startup', 'VC Firm', 'Private Company', 'Incubator', 'SaaS', 'Mobile App', None]\n",
        "stages = ['Seed', 'Series A', 'Series B', 'Series C', 'Acquired', None]\n",
        "techs = ['Python', 'Javascript', 'HTML5', 'Java', 'CSS', None]\n",
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "for type_ in types[2:]:\n",
        "    for stage in stages:\n",
        "        for tech in techs:\n",
        "            for query in queries:\n",
        "                print(query, type_, stage, tech)\n",
        "\n",
        "                try:\n",
        "                    companies = get_companies(query, type_, stage, tech)\n",
        "                    companies['query'] = query\n",
        "                    companies['type_'] = type_\n",
        "                    companies['stage'] = stage\n",
        "                    companies['tech'] = tech\n",
        "                    print('Done')\n",
        "                except Exception as e: \n",
        "                    companies = pd.DataFrame()\n",
        "                    print('Could not get companies')\n",
        "                    print('\\n')\n",
        "                    print(e)\n",
        "                    print('\\n')\n",
        "                    pass\n",
        "\n",
        "                try:\n",
        "                    if df.empty:\n",
        "                        df = companies\n",
        "                    else:\n",
        "                        df = df.append(companies)\n",
        "                except:\n",
        "                    print('Unable to append new data.')\n",
        "                    pass\n",
        "                    \n",
        "            df = df.reset_index(drop=True)\n",
        "            df.to_csv('ai_startups.csv')\n",
        "            print(df.location.head())\n",
        "                    \n",
        "            \n",
        "df = df.reset_index(drop=True)\n",
        "df.to_csv('ai_startups.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "artificial intelligence Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "machine learning Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "data science Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "big data Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "neural network Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "deep learning Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "natural language processing Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "transfer learning Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "reinforcement learning Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "nlp Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "recurrent neural Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "convolution neural Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "data mining Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "data extraction Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "data engineering Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "web scraping Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "web scrape Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "web crawler Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "web crawling Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "evolutionary computation Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "genetic algorithm Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "genetic programming Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "object recognition Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "image understanding Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "speech processing Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            " speech recognition Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "machine translation Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "time series Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "ai Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "intelligent machine Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "pattern recognition Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n",
            "computer vision Private Company Seed Python\n",
            "Could not get companies\n",
            "\n",
            "\n",
            "Message: unknown error: Chrome failed to start: exited abnormally.\n",
            "  (unknown error: DevToolsActivePort file doesn't exist)\n",
            "  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-6d61d927afd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ai_startups.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'location'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2AL3e-z5fAG",
        "colab_type": "text"
      },
      "source": [
        "##Step 3. Matching job listings to resumes with cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxf5mc9Jw8OA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4dcd79e3-a19c-48ce-f5a7-e6f314e73bd1"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/AVJdataminer/HireOne/master/data/job_descriptions.csv', encoding = 'unicode_escape')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jobOrResumeDescription</th>\n",
              "      <th>role</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>: Artificial Intelligence / Machine Learning D...</td>\n",
              "      <td>Developer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>: Data Scientist/Architect\\n: 6+ months + Hig...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>: Data Analyst\\n: Davidson, NC\\n: 04+ Months\\...</td>\n",
              "      <td>Data Analyst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: Big Data Architect or Data Scientist\\n: New...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>: Data Engineer\\n: Woonsocket, RI\\n: 6+ Months...</td>\n",
              "      <td>Data Engineer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              jobOrResumeDescription            role\n",
              "0  : Artificial Intelligence / Machine Learning D...       Developer\n",
              "1   : Data Scientist/Architect\\n: 6+ months + Hig...  Data Scientist\n",
              "2   : Data Analyst\\n: Davidson, NC\\n: 04+ Months\\...    Data Analyst\n",
              "3   : Big Data Architect or Data Scientist\\n: New...  Data Scientist\n",
              "4  : Data Engineer\\n: Woonsocket, RI\\n: 6+ Months...   Data Engineer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzYIKHX8HMXC",
        "colab_type": "text"
      },
      "source": [
        "Clean up job description column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UK0cxBZw8NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace('\\n', ' ')                # remove newline\n",
        "    text = text.replace(':', ' ')\n",
        "    return text\n",
        "df['description'] = df.apply(lambda x: clean_text(x['jobOrResumeDescription']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3zxu0UuHqG4",
        "colab_type": "text"
      },
      "source": [
        "Print first job desc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6NG3nbDKvOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "c9063081-4ac7-4acc-f889-9129ca8dfc29"
      },
      "source": [
        "df['description'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"  Artificial Intelligence / Machine Learning Developer     Irving TX  Terms  Contract   Details             Bachelor's degree or 7-10 or more years of relevant  experience.     7+ years of server app development (design/develop/deploy).     3+ years of Python 3.x, experience in ML algorithms/data analytics.     5+ years of advanced SQL development (ER modeling, SQL scripts, stored procedures, functions, s) with RDBMS such as PostgreSQL/MS SQL Server.     3+ years on AWS S3, EC2, Serverless computing (Lambda).     3+ years of experience/familiarity with DevOps using Stash/Jenkins/Chef and Puppet.     Excellent communication  in interfacing with different cross-functional teams.         5+ years of experience in designing, building applications using .NET platform using C#, .NET Core, ORM, SQL, MS SQL Server, Visual Studio.     1+ years' experience in developing containerized Docker .net core apps.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yom1LRGaIc9J",
        "colab_type": "text"
      },
      "source": [
        "Create a list from the cleaned job description column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE6II7vhIhxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jd = df['description'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Q8puCuIQEu",
        "colab_type": "text"
      },
      "source": [
        "Build model to tag each job description as a seperate document.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhMYG7L6Md3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53e0834d-9a4f-4888-fce8-1b7e4c494dea"
      },
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim import models\n",
        "# Create the tagged document needed for Doc2Vec\n",
        "def create_tagged_document(list_of_list_of_words):\n",
        "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
        "        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
        "\n",
        "train_data = list(create_tagged_document(jd))\n",
        "\n",
        "print(train_data[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TaggedDocument(words=\"  Artificial Intelligence / Machine Learning Developer     Irving TX  Terms  Contract   Details             Bachelor's degree or 7-10 or more years of relevant  experience.     7+ years of server app development (design/develop/deploy).     3+ years of Python 3.x, experience in ML algorithms/data analytics.     5+ years of advanced SQL development (ER modeling, SQL scripts, stored procedures, functions, s) with RDBMS such as PostgreSQL/MS SQL Server.     3+ years on AWS S3, EC2, Serverless computing (Lambda).     3+ years of experience/familiarity with DevOps using Stash/Jenkins/Chef and Puppet.     Excellent communication  in interfacing with different cross-functional teams.         5+ years of experience in designing, building applications using .NET platform using C#, .NET Core, ORM, SQL, MS SQL Server, Visual Studio.     1+ years' experience in developing containerized Docker .net core apps.\", tags=[0])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsndaLppIhJv",
        "colab_type": "text"
      },
      "source": [
        "Train the model on the job descriptions for matching later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIri67T3IlaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Init the Doc2Vec model\n",
        "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
        "\n",
        "# Build the Volabulary\n",
        "model.build_vocab(train_data)\n",
        "\n",
        "# Train the Doc2Vec model\n",
        "model.train(train_data, total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gXtAilyI07r",
        "colab_type": "text"
      },
      "source": [
        "Let's look at an example of how it converts a list of words to a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lbisgLtIyIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "77209aaa-f0a9-4890-bdb8-bf0d06a75efd"
      },
      "source": [
        "print(model.infer_vector(['data', 'science','python']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-9.0049580e-04  9.3729707e-04  9.5215701e-03 -7.1332399e-03\n",
            "  9.0731680e-03 -8.5485503e-03  4.2979093e-03 -4.2492119e-03\n",
            " -8.3840443e-03  3.9002204e-03 -3.4895353e-04  2.9707795e-03\n",
            "  2.8806978e-03 -8.9825261e-03 -9.9531878e-03  1.2313742e-03\n",
            " -6.2231650e-03  6.6197319e-03  1.2553034e-03 -9.8728556e-03\n",
            " -4.0492681e-03 -3.0378737e-03  7.1065989e-03  4.3371865e-03\n",
            " -8.7247863e-03 -5.8196560e-03 -2.3256943e-03 -5.5077695e-03\n",
            " -8.3275102e-03 -4.8710499e-03  6.0714810e-05  8.4586637e-03\n",
            "  8.4094070e-03 -4.1162362e-03 -3.1165923e-03 -3.5291738e-03\n",
            "  8.7357946e-03 -3.0260670e-03  5.8570039e-03 -3.5897845e-03\n",
            " -5.4527395e-03  4.2740526e-03  5.5681253e-03  5.8630719e-03\n",
            " -5.9407563e-03 -6.8237288e-03 -3.7333095e-03  4.1679246e-03\n",
            " -5.9044352e-03  7.9363724e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FBp0Z2fMmd-",
        "colab_type": "text"
      },
      "source": [
        "Here we apply the model to each job description in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83wjxiCoMl46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "for i in range(len(jd)):\n",
        "    data.append(model.docvecs[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BeFuMMLJAB6",
        "colab_type": "text"
      },
      "source": [
        "## Now let's load the text from our resume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vD2ko0AKL-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "143fe088-77b0-4ddc-ffcd-27964375911b"
      },
      "source": [
        "resume = pd.read_csv('https://raw.githubusercontent.com/AVJdataminer/HireOne/master/data/resumes.csv', encoding = 'unicode_escape')\n",
        "resume.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jobOrResumeDescription</th>\n",
              "      <th>role</th>\n",
              "      <th>sourceType</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Â  with around 5 years of experience in all p...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>resume</td>\n",
              "      <td>Â  with around 5 years of experience in all p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n \\nData scientist with a strong math backgro...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>resume</td>\n",
              "      <td>Data scientist with a strong math backgroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n\\n\\n* Around 4+  years of experience in Data...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>resume</td>\n",
              "      <td>* Around 4+  years of experience in Data An...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n\\nExpert in logical and problem-solving  wit...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>resume</td>\n",
              "      <td>Expert in logical and problem-solving  with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Experienced  with 2+ years of hands-on experie...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>resume</td>\n",
              "      <td>Experienced  with 2+ years of hands-on experie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              jobOrResumeDescription  ...                                        description\n",
              "0  Â  with around 5 years of experience in all p...  ...  Â  with around 5 years of experience in all p...\n",
              "1  \\n \\nData scientist with a strong math backgro...  ...     Data scientist with a strong math backgroun...\n",
              "2  \\n\\n\\n* Around 4+  years of experience in Data...  ...     * Around 4+  years of experience in Data An...\n",
              "3  \\n\\nExpert in logical and problem-solving  wit...  ...    Expert in logical and problem-solving  with ...\n",
              "4  Experienced  with 2+ years of hands-on experie...  ...  Experienced  with 2+ years of hands-on experie...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzdqFARmLUW0",
        "colab_type": "text"
      },
      "source": [
        "We only need one resume to start with so let's select the first one and split into words to push into our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeZUSh18P_Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r1 = resume['description'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blLQ9AqBLblu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resume = resume['description'].iloc[0].split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXdIQ6qzMNxv",
        "colab_type": "text"
      },
      "source": [
        "Review the resulting vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3ciaV5xMH-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d314c6af-4fb6-4715-f0b3-b991e0b136a6"
      },
      "source": [
        "print(model.infer_vector(resume))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.2703119   0.46140584  1.3335586   0.194047    0.3511251  -0.05135229\n",
            "  1.2376658   1.104154    0.6905708  -0.66995645  0.00775168  1.7607471\n",
            " -0.56709665  0.71579945  1.4739642  -0.98076457 -0.70780426  0.93041635\n",
            " -0.38668808  0.03639724 -0.569789    0.30209452  1.1538218  -0.1179663\n",
            " -0.64267266 -0.57093453  0.14116059 -0.3806373   0.542782   -0.4670417\n",
            " -0.9182177  -0.00489526  2.1500022  -0.5747738   0.09500379 -0.12688264\n",
            "  0.07573358  0.37014386 -1.56851     0.15511167 -0.06379291 -0.63691014\n",
            "  0.957231    1.1769577  -1.1278763   0.05250629  0.93851274  0.62922686\n",
            " -0.03870421 -0.44639188]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdG-iOPhMTJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resume_vect = model.infer_vector(resume)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYvrFWw9M4dh",
        "colab_type": "text"
      },
      "source": [
        "## Compare our resume to the job descriptions using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY7SGrOwMbgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "50405b4c-ee60-48e2-db15-27d0d7ce4540"
      },
      "source": [
        "def plot_pca(data):\n",
        "    from sklearn.decomposition import PCA\n",
        "    pca = PCA(n_components=2) #, whiten=True\n",
        "    X = pca.fit_transform(data)\n",
        "    xs,ys =X[:,0], X[:,1]\n",
        "    plt.scatter(X[:,0], X[:,1])\n",
        "    plt.scatter(xs[-1], ys[-1], c='Red', marker='+')\n",
        "    plt.text(xs[-1], ys[-1],'resume')\n",
        "    plt.grid()\n",
        "    plt.suptitle('PCA')\n",
        "    #plt.savefig('distance_PCA_improved.png')\n",
        "    plt.show()\n",
        "plot_pca(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyMDvR4-NG3d",
        "colab_type": "text"
      },
      "source": [
        "## Calculate the cosine distances between our resume and each of the job descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZYbYjokM-KO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "cos_dist =[]\n",
        "for i in range(len(data)):\n",
        "    cos_dist.append(float(cosine_distances(resume_vect[0:].reshape(1,-1),data[i].reshape(1,-1))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf_bGHdyNja6",
        "colab_type": "text"
      },
      "source": [
        "create a key words list for each job description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYzteudNgqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key_list =[]\n",
        "\n",
        "for j in jd:\n",
        "    key =''\n",
        "    for word in keywords(j).split('\\n'):\n",
        "        key += '{} '.format(word)\n",
        "    key_list.append(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whc0xp1xNa4y",
        "colab_type": "text"
      },
      "source": [
        "Create a nice data frame to put the scores and keywords together. Print out the first 10 lowest scores. Those jobs will the most similar to the resume."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM85b1XbNW_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "4b0136da-7d70-474c-885d-0e5cece648ab"
      },
      "source": [
        "role = df['role'].tolist()\n",
        "summary = pd.DataFrame({\n",
        "        'Role Title': role,\n",
        "        'Cosine Distances': cos_dist,\n",
        "        'Keywords': key_list,\n",
        "        'Job Description': jd\n",
        "    })\n",
        "z = summary.sort_values(by ='Cosine Distances', ascending=True)\n",
        "z.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Role Title</th>\n",
              "      <th>Cosine Distances</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Job Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>0.408452</td>\n",
              "      <td>knowledge engineer experience learning data th...</td>\n",
              "      <td>- Data Scientist / Data Engineer    - Chica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>0.493039</td>\n",
              "      <td>knowledge experience learning scientist theano</td>\n",
              "      <td>Data Scientist    Chicago, IL    Contract &amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>0.605699</td>\n",
              "      <td>experience data lead leading time bdm field di...</td>\n",
              "      <td>Big Data Lead    Raritan- NJ    -12 months  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>0.616657</td>\n",
              "      <td>experience experiments data models model model...</td>\n",
              "      <td>Data Scientist     Richardson, TX    Full T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>0.632020</td>\n",
              "      <td>computational high computing numerical methods...</td>\n",
              "      <td>Applied Computational Mathematician / Engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>0.661276</td>\n",
              "      <td>solutions like perform alternative solution pr...</td>\n",
              "      <td>Sr. Business Analyst UC Innovation - Irvine, C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>0.680710</td>\n",
              "      <td>data experience including providing business m...</td>\n",
              "      <td>Senior Healthcare Data Analyst Advantmed98 re ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>0.688905</td>\n",
              "      <td>experience data business solutions strong team...</td>\n",
              "      <td>-Lead BI    - Cheektowaga, NY   -Full Time ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Developer</td>\n",
              "      <td>0.692190</td>\n",
              "      <td>years developer development developing sql ser...</td>\n",
              "      <td>Artificial Intelligence / Machine Learning D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>0.719788</td>\n",
              "      <td>data processing process models good solutions ...</td>\n",
              "      <td>Big Data Architect DE, PA, NJ, NYC, MA s (50-6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Role Title  ...                                    Job Description\n",
              "34  Data Scientist  ...     - Data Scientist / Data Engineer    - Chica...\n",
              "35  Data Scientist  ...     Data Scientist    Chicago, IL    Contract &...\n",
              "20  Data Scientist  ...    Big Data Lead    Raritan- NJ    -12 months  ...\n",
              "30  Data Scientist  ...     Data Scientist     Richardson, TX    Full T...\n",
              "98   Data Engineer  ...  Applied Computational Mathematician / Engineer...\n",
              "76    Data Analyst  ...  Sr. Business Analyst UC Innovation - Irvine, C...\n",
              "72    Data Analyst  ...  Senior Healthcare Data Analyst Advantmed98 re ...\n",
              "24  Data Scientist  ...     -Lead BI    - Cheektowaga, NY   -Full Time ...\n",
              "0        Developer  ...    Artificial Intelligence / Machine Learning D...\n",
              "37   Data Engineer  ...  Big Data Architect DE, PA, NJ, NYC, MA s (50-6...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y2zTt1XPpFE",
        "colab_type": "text"
      },
      "source": [
        "Let's print the first job description and our resume text to visually compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGRBAfmPPnZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6207ec44-3a5e-4414-ef5a-fbacf1de7f1d"
      },
      "source": [
        "z['Job Description'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'   - Data Scientist / Data Engineer    - Chicago, IL    - Long Term  Exp Req  - 8+ Years        -      Senior data scientist / engineer      Financial Domain Knowledge & experience     Strong Experience in AI related      Knowledge & exposure in rendering ML functionality     Understanding  AI/Deep Learning algorithm such as CNN, RNN, LSTM     Experience in building AI based NLP and OCR solution using Keras, Google Tensorflow, Theano, Caffe 2 etc? '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M8mMowlP5OB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "d13b3aff-57a3-47e9-9944-697a9be86afc"
      },
      "source": [
        "r1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"Â\\x95  with around 5 years of experience in all phases of diverse   specializing in Data Science, Big Data, Azure Machine Learning, Google Cloud and Tableau, using Cloud based infrastructure.   Â\\x95 ed on analyzing large datasets on distributed databases and developing Machine Learning algorithms to gain operational insights and present them to the leadership.   Â\\x95 Extensively ed on Data preparation, exploratory analysis, Feature engineering using supervised and unsupervised modeling.   Â\\x95 Experienced the full software life cycle in SDLC, Agile and Scrum methodologies.   Â\\x95 Expert in using of statistical  and programming languages (R, Python, C, C++, Java, SQL, UNIX)   Â\\x95 Adapted statistical programming languages like R and Python   Â\\x95 Well-versed with Linear/non-linear, regression and classification modeling predictive algorithms.   Â\\x95 Actively involved in model selection, statistical analysis using SAS and Gretl statistical tool.   Â\\x95 Created dashboards as part of Data Visualization using Tableau.   Â\\x95 Proficiency in using Spark for Bigdata processing in the Hadoop/DataProc/ EMRE ecosystem.   Â\\x95 Performed preliminary data analysis using descriptive statistics and handled anomalies such as removing duplicates and imputing missing values using Talend tool.   Â\\x95 Performed Dimensionality reduction using principal component analysis, auto encoders, and t-SNE.   Â\\x95 Validate the consolidated data and develop the model that best fits the data. Interpret data from multiple sources, consolidate it, and perform data cleansing using R/Python/Spark.   Â\\x95 Performed multiple Data Mining techniques and derive new insights from the data.   Â\\x95 Skilled in Machine Learning, Statistical Modeling, and Big Data.   Â\\x95 Creative problem-solver with strong analytical, leadership, and communication    Â\\x95 Proficient in Python, R, Scala, Java, SQL, and C   Â\\x95 Experienced in Machine Learning, Data mining with large datasets of Structured and Unstructured Data, Data Acquisition, Data Validation, and Predictive Modeling   Â\\x95 Data Science Specialties include: Machine Learning, Sequential Modeling, Natural Language Processing (NLP)   Â\\x95 Use of Analytical : Bayesian Analysis, Inference, Time-Series Analysis, Regression Analysis, Linear models, Multivariate analysis, Sampling methods, Forecasting, Segmentation, Clustering, Sentiment Analysis, Part of Speech Tagging, and Predictive Analytics   Â\\x95 Experienced in stochastic optimization and regression with machine learning algorithms   Â\\x95 Experienced in formulating and solving discrete and continuous optimization problems   Â\\x95 Able to research statistical machine learning, supervised learning, and classification methods   Â\\x95 Strong mathematical and statistical modeling and computer programming  in an innovative manner   Â\\x95 Use of Various Analytics : Classification and Regression Trees (CART), Support Vector Machine (SVM), Random Forest, Gradient Boosting Machine (GBM), Principal Component Analysis (PCA), Regression, NaÃ¯ve Bayes, Support Vector Machines   Â\\x95 Experienced in AWS cloud computing, Spark, and capable of ing with large datasets   Â\\x95 Deep Learning: Machine perception, Data Mining, Machine Learning algorithms, Neural Nets, TensorFlow, Keras   Â\\x95 Delivered presentations and highly  reports; collaboration with stakeholders and cross-functional teams, advisement on how to leverage analytical insights   Â\\x95 Development of clear analytical reports which directly address strategic goals   Â\\x95 Identified and learn applicable new techniques independently as needed   Â\\x95 Able to  comfortably and effectively within an interdisciplinary research environment   Â\\x95 Experienced with validation of machine learning ensemble classifiers   Â\\x95 Utilized the online datasets to implement machine learning models using Spark ML for building prototypes  Willing to relocate: Anywhere  Authorized to  in the US for any employer   Experience  Data Science Engineer  Jefferies LLC - Jersey City, NJ  February 2019 to Present  Responsibilities:   Â\\x95 Coded in Python with selenium and automated website data scraping   Â\\x95 Scripted using R for cleaning, merging and extraction of relevant data   Â\\x95 Created interactive visualization using Tableau and performed data analysis to report findings and trends   Â\\x95 Analyzed massive data models with tables having over 100s of millions of records to draw insights and useful information.   Â\\x95 Architect complex database systems on Hadoop to scale out data development processes.   Â\\x95 Explore  and gather insights from Amfam's operational data stores and data warehouses (stored in Oracle, Greenplum, HDFS and S3) by querying them and creating data visualizations (in Tableau).   Â\\x95 Designed and developed scripts to test data and find data defects.   Â\\x95 Determined the quality of data, verify accuracy of information and ensure that the data is fit for modeling purposes.   Â\\x95 Transformed data elements and attributes into usable form based on business requirements.   Â\\x95 Blend data sets at different granularity levels using analytical queries, window functions and SQL joins.   Â\\x95 Identified data duplicates and develop means to remove them.   Â\\x95 Analyzed tabular data to determine or alter their grain (drill down or roll up) using analytical queries, MapReduce or python.   Â\\x95 Designed and develop data pipelines to preprocess modeling data such as handle null values and clean up defective data attributes.   Â\\x95 Developed Spark code to parse out and transform semi structured data such as XMLs, JSONs and CSVs into hive tables or data frames.   Â\\x95 Explored and determined ways to organize data in Hive tables for fast read and writes through hive table partitions and buckets for optimized performance.   Â\\x95 Developed programs to store data in appropriate file formats and logical grouping in tables.   Â\\x95 Optimized code and queries to run faster and efficiently. Optimize ETL processes for distributed data marts on Hadoop   Â\\x95 Maintained development activities in version control and create updated documentation.      Environment: HADOOP (HDFS) Horton s, AWS, SPARK, Python, Java, Hive, Beeline, Apache pig, Tableau, SAS, Oracle, DB2, MySQL  Data Scientist  Anthem - Atlanta, GA  June 2018 to February 2019  Responsibilities:   Â\\x95 Translated business questions into research s, design and conduct analyses, develop findings and synthesize recommendations to deliver valuable, relevant, and actionable insights   Â\\x95 Strong track record of contributing to successful end-to-end analytic solutions (clarifying business s and hypotheses, communicating project deliverables and timelines, and informing action based on findings)   Â\\x95 Used Pandas, NumPy, Scikit-Learn in Python for performing exploratory analysis and developing various machine learning models such Random forest   Â\\x95 The missing data in the dataset is handled using Imputer method in SkLearn library   Â\\x95 Performed categorical variable analysis using python Label Encoder, fit transform, One Hot Encoder methods in sklearn library   Â\\x95 Responsible for design and development of advanced R/Python programs to prepare to transform and harmonize data sets in preparation for modeling   Â\\x95 Defined a generic classification function, which takes a model as input and determines the Accuracy and Cross-Validation scores   Â\\x95 Advanced SQL ability to efficiently  with very large datasets. Ability to deal with non-standard machine learning datasets   Â\\x95 Built forecasting models in Python using Gradient Boost Regression Trees. Forecasted the revenue for future   Â\\x95 ed with applied statistics and applied mathematics  for performance optimization   Â\\x95 ed with K-Means clustering and Hierarchical clustering algorithm to do segmentation of stores   Â\\x95 Collected various store attributes and added them into our segmentation model in order to better classify different segments using clustering algorithms   Â\\x95 Used cross-validation to test the models with different batches of data to optimize the models and prevent over fitting   Â\\x95 Analyzed the SQL scripts and designed the solution to implement using PySpark and developed scripts as per the requirement   Â\\x95 ed with Tableau in order to represent the data in visual format and better describe the problem with solutions.      Environments: Python, PyCharm, Jupyter, Notebook, Spyder, R, Tableau, MySQL  Data Scientist  US Bank - Brookfield, WI  September 2017 to June 2018  Responsibilities:   Â\\x95 Used SQL alongside a variety or reporting  - BusinessObjects, Power BI, Tableau - to develop operational and visual reports for KPI monitoring   Â\\x95 Data analysis and visualization (Python, R)   Â\\x95 Designed, implemented and automated modeling and analysis procedures on existing and experimentally created data   Â\\x95 Increased pace & confidence of learning algorithm by combining state of the art  and statistical methods; provided expertise and assistance in integrating advanced analytics into ongoing business processes   Â\\x95 Parsed data, producing concise conclusions from raw data in a clean, well-structured and easily maintainable format   Â\\x95 Implemented Topic Modelling, linear classifier models   Â\\x95 Collaborate with UI engineers, project managers, and designers to develop web portal that aggregates reports from various sources and    Â\\x95 Member of Data Science team tasked with helping clients turn data into a strategic asset   Â\\x95 Focused on front end features, browser manipulation, and cross-browser compatibility.   Â\\x95 Utilize  expertise including HTML5, CSS3, JavaScript, JQUERY, HTML, Node.js, Angular.js, and DOM to develop reporting portal.   Â\\x95 Used Agile Scrum for BI  across different clients, which allowed for production prototyping, rapid deployment and transparency.      Environment: Tableau, SQL, Java, HTML, Oracle, Agile, Hadoop.  Junior Data Scientist  Ordnance Factory Board - IN  January 2016 to July 2017  Description: Built a new team and managed in designing cost effective A/B tests to determine high performance marketing campaigns and contributed to increase in sales by 20% and reduced the promotional cost by 35%.      Responsibilities:   Â\\x95 ed on various phases of data mining- data collection, data cleaning, developing models, validation, visualization.   Â\\x95 Captured Modelling requirements from Senior Stakeholders to fetch functional requirements for SAS/R, Python.   Â\\x95 Performed Data Manipulation and Aggregation from various sources including HDFS and created various Predictive and Descriptive analytics using R and Tableau.   Â\\x95 Used various libraries and developed various matching learning algorithms using Pandas, NumPy, Seaborn, Scipy, matplotlib, Scikit-learn in python.   Â\\x95 Designed Predictive analysis algorithms using Historical Data.   Â\\x95 Utilized machine learning algorithms as well as implemented algorithms such as Decision Tree, linear regression, multivariate regression, Naive Bayes, Random Forests, K-means, & KNN.   Â\\x95 ed on Map Reduce/Spark Python modules for machine learning and predictive analytics in Hadoop on AWS.   Â\\x95 ed on Reporting tool (Tableau) Test, Validate Data Integrity of Reports.      Environment: Python, I Python, Scikit-Learn, MySQL, SQL, NoSQL, Data Modelling, Data Warehouse, Hadoop (MapReduce, HBase, Hive), Gradient Boost, Random Forest, Neural Nets, Sklearn etc.  Data Science Intern  iPrism Technologies - Hyderabad, Telangana  April 2015 to December 2015  Description: The project was to build a classification model predicting the probability of a customer who will not subscribe to paid membership, to help the marketing team to focus on improving the subscription rate.   Responsibilities:   Â\\x95 Collected data from end client, performed ETL and defined the uniform standard format   Â\\x95 Wrote queries to retrieve data from SQL Server database to get the sample dataset containing basic fields   Â\\x95 Performed string formatting on the dataset converting hours from date format to a numerical integer   Â\\x95 Used Python libraries like Matplotlib and Seaborn to visualize the numerical columns of the dataset such as day of week, age, hour and number of screens.   Â\\x95 Developed and implemented predictive models like Logistic Regression, Decision Tree, Support Vector Machine (SVM) to predict the probability of enrollment   Â\\x95 Used Ensemble learning methods like Random Forest, Bagging & Gradient Boosting& picked the final model based on confusion matrix, ROC & AUC & predicted the probability of customer enrollment   Â\\x95 Tuned the hyper parameters of the above models using Grid Search to find the optimum models   Â\\x95 Designed and implemented K-Fold Cross-validation to test and verify the model's significance   Â\\x95 Developed a dashboard and story in Tableau showing the benchmarks and summary of model's measure.      Environment: SQL Server 2012/2014, Python 3.x (Scikit-Learn, NumPy, Pandas, Matplotlib, Dateutil, Seaborn), Tableau, Hadoop  Education  Master's in Computer Engineering in Data Science and Analytics  Arizona State University - Tempe, AZ    Apache spark, Hadoop, Hive, Javascript, D3.js, Mapreduce, Natural, Pig, Python, Mapreduce, Data science, Hadoop, Machine learning, Natural language processing, Nosql, Ms sql server, Sql server, Mysql, Pl/sql, Sql  Additional Information   :   Programming languages Python, Java, R. C   Data  and Frames s Hadoop (Apache Spark, Pig, Hive, MapReduce), D3.js, Tableau, MATLAB, R-Studio   Data Science Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Neural Nets, Machine Perception   Operating systems Windows, Linux.   Databases MySQL, MS SQL Server, NoSQL   Web and Cloud Technologies AWS, HTML5   Languages Python 3.7, SQL, R 3.6, Java, JavaScript, PL/SQL\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiuCjeStOYUB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let's test it out on another resume or dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1EG7ZhrOJyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv('https://raw.githubusercontent.com/JimKing100/techsearch/master/data/techsearch_p1.csv')\n",
        "df1 = df1.drop(df1.columns[0], axis=1)\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/JimKing100/techsearch/master/data/techsearch_p2.csv')\n",
        "df2 = df2.drop(df2.columns[0], axis=1)\n",
        "both_df = pd.concat([df1, df2], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMVm-XbrQZjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "bb92079c-21b7-4afe-b9b5-09d18f046034"
      },
      "source": [
        "both_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>counts</th>\n",
              "      <th>city</th>\n",
              "      <th>job</th>\n",
              "      <th>low_salary</th>\n",
              "      <th>high_salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist (All Levels) - Santa Clara</td>\n",
              "      <td>LeanTaaS</td>\n",
              "      <td>Santa Clara, CA 95050</td>\n",
              "      <td>Help build technology that saves lives!\\n\\nWe'...</td>\n",
              "      <td>1259</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist (Intern) - United States</td>\n",
              "      <td>Cisco Careers</td>\n",
              "      <td>San Jose, CA</td>\n",
              "      <td>What You‚Äôll DoAcquire, clean and structure d...</td>\n",
              "      <td>1259</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>Stanford, CA</td>\n",
              "      <td>Data Scientist (Data Analyst 2)\\nJob Family: I...</td>\n",
              "      <td>1259</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist in Santa Clara, CA (corp-corp c...</td>\n",
              "      <td>Advantine Technologies</td>\n",
              "      <td>Santa Clara, CA</td>\n",
              "      <td>Job Description\\n\\nTitle : Data Scientist\\nLoc...</td>\n",
              "      <td>1259</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Palo Verde Consulting</td>\n",
              "      <td>Campbell, CA 95008</td>\n",
              "      <td>Job Title: Data ScientistLocation: Campbell, C...</td>\n",
              "      <td>1259</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>150000.0</td>\n",
              "      <td>210000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           job_title  ... high_salary\n",
              "0          Data Scientist (All Levels) - Santa Clara  ...         NaN\n",
              "1            Data Scientist (Intern) - United States  ...         NaN\n",
              "2                                     Data Scientist  ...         NaN\n",
              "3  Data Scientist in Santa Clara, CA (corp-corp c...  ...         NaN\n",
              "4                                     Data Scientist  ...    210000.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLcPJxjoQ8pL",
        "colab_type": "text"
      },
      "source": [
        "If you feel like you've got it, go ahead apply the steps we used up above on the job descriptions in this new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_IwTIVUQbtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05798f38-bda3-4222-ac9e-40e441cccbc7"
      },
      "source": [
        "both_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7827, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra2EJpcIAyrZ",
        "colab_type": "text"
      },
      "source": [
        "## Step 5. Build a Streamlit.io App from model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo18ZQy1A4_i",
        "colab_type": "text"
      },
      "source": [
        "Starting with running the demo app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef-wi9H418ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJuVVsVdBODZ",
        "colab_type": "text"
      },
      "source": [
        "Install streamlit module, ignore the warning about the wrong version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPxfsHGb5_xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5075a85d-cd74-4b99-c65a-483cb116a2ad"
      },
      "source": [
        "!pip install streamlit -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.1MB 2.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 47.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4MB 38.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 47.4MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtJg-sSlBii8",
        "colab_type": "text"
      },
      "source": [
        "Install ngrok helper module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC3gSHfd6J9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "929e6b77-8b6e-49b9-83ea-842673a15a42"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-29 21:06:57--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.5.250.138, 52.21.101.90, 54.152.45.100, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.5.250.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  13%[=>                  ]   1.84M  8.96MB/s               \r        ngrok-stabl  33%[=====>              ]   4.34M  10.7MB/s               \r       ngrok-stable  53%[=========>          ]   6.96M  11.4MB/s               \r      ngrok-stable-  76%[==============>     ]  10.04M  12.3MB/s               \r     ngrok-stable-l  99%[==================> ]  13.00M  12.8MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  12.9MB/s    in 1.0s    \n",
            "\n",
            "2020-07-29 21:06:58 (12.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE8YZYsk-UGs",
        "colab_type": "text"
      },
      "source": [
        "**Use the output of this command as the link to your Streamlit app.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMOoOLFT88ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9a23f44-ae2a-41c2-e577-6f50a50b324b"
      },
      "source": [
        "#This cell makes the working link after last cell is run.\n",
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://19a0218f885c.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdNVtkKn-l-z",
        "colab_type": "text"
      },
      "source": [
        "Get the Streamlit demo app running. **Ignore the output urls from this** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUHzaig59IQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "22f6b203-7642-4a71-e21d-9d054a0e076f"
      },
      "source": [
        "!streamlit hello"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  Welcome to Streamlit. Check out our demo in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.231.115.65:8501\u001b[0m\n",
            "\u001b[0m\n",
            "  Ready to create your own Python apps super quickly?\u001b[0m\n",
            "  Just head over to \u001b[0m\u001b[1mhttps://docs.streamlit.io\u001b[0m\n",
            "\u001b[0m\n",
            "  May you create awesome apps!\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faZP4IK8CI2l",
        "colab_type": "text"
      },
      "source": [
        "Now, go back and click on the link in the previous cell that ends in 'ngrok.io' to view the demo in your browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOZC8zufaF0X",
        "colab_type": "text"
      },
      "source": [
        "- When you are done reviewing the demo stop this cell by clicking on the stop button.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMLKbLDdCoO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}